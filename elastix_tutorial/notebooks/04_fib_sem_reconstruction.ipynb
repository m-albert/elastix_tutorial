{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7e48bb98-6b83-44f3-abcf-f28180921d24",
   "metadata": {},
   "source": [
    "# 4. FIB-SEM reconstruction\n",
    "\n",
    "In this notebook we'll use elastix to\n",
    "- reconstruct a FIB-SEM dataset\n",
    "- perform drift correction of a timelapse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "25426eab-8f97-48c8-9f72-7128b52f0154",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from skimage import io\n",
    "import itk\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb47a25f-e90c-47fa-b3de-7b49f81f9c7e",
   "metadata": {},
   "source": [
    "## FIB-SEM reconstruction\n",
    "\n",
    "FIB-SEM is a volumetric imaging technique in which\n",
    "- the surface of a block is imaged using Scanning Electron Microscopy (SEM)\n",
    "- the top layer of the block is ablated using a Focused Ion Beam (FIB)\n",
    "- this is repeated n times to obtain a volume of n slices\n",
    "\n",
    "Typically the slices exhibit deformations with respect to each other and a high quality 3D stack can be reconstructed by registering slices sequentially.\n",
    "![image.png](schematics/fib_sem.png)!\n",
    "\n",
    "(from Briggman and Bock, Curr. Op. in Neurobiol. 2012)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9963df1c-1904-40c3-98b6-8e6de86c3e7b",
   "metadata": {},
   "source": [
    "### Load and visualize the data\n",
    "\n",
    "The image used is a subset of the dataset available here:\n",
    "https://www.ebi.ac.uk/bioimage-archive/galleries/EMPIAR-10479/IM1.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "86be7064-7326-40da-afaa-d3f1efcd87f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "im = io.imread('../example_data/fibsem.tif')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "17990f40-d559-4133-a731-e4c6e583d5cf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Image layer 'im' at 0x179fb0950>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# visualise\n",
    "\n",
    "import napari\n",
    "viewer = napari.Viewer()\n",
    "\n",
    "viewer.add_image(im)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d205e9ae-32b6-46e0-92b7-e3b0a1079df6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image shape is [41, 168, 251] in z, y, x\n"
     ]
    }
   ],
   "source": [
    "n_slices = im.shape[0]\n",
    "print('Image shape is %s in z, y, x' %list(im.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d9ef8b2-0397-4f17-b117-91b494a3e877",
   "metadata": {},
   "source": [
    "### Defining the registration parameters\n",
    "\n",
    "For FIB-SEM acquisitions, registration typically requires nonlinear registration. Here, we perform first a linear and then a nonlinear transformation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e229498f-0805-45f8-864e-33f7183f9ace",
   "metadata": {},
   "outputs": [],
   "source": [
    "registration_parameter_object = itk.ParameterObject.New()\n",
    "\n",
    "registration_parameter_object.AddParameterMap(itk.ParameterObject.New().GetDefaultParameterMap('translation'))\n",
    "pmap_bspline = itk.ParameterObject.New().GetDefaultParameterMap('bspline')\n",
    "pmap_bspline['GridSpacingSchedule'] = [str(v) for v in [10] * 4]\n",
    "\n",
    "registration_parameter_object.AddParameterMap(pmap_bspline)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61d5aab5-a47d-446a-868c-950cf8276635",
   "metadata": {},
   "source": [
    "### Reconstruction\n",
    "\n",
    "Our strategy will be to\n",
    "- choose the first slice as a reference slice\n",
    "- register neighboring slices to each other\n",
    "- transform each slice by chaining together all pairwise transformations between the slice and the reference slice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f1282526-3f1c-454d-858b-33422056942e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 40/40 [00:51<00:00,  1.28s/it]\n"
     ]
    }
   ],
   "source": [
    "# initialise the corrected stack as a list, containing the unmodified reference slice\n",
    "corrected_slices = [im[0]]\n",
    "\n",
    "# initialise a parameter object to which the transforms will be appended that result from the pairwise slice registrations\n",
    "curr_transform_object = itk.ParameterObject.New()\n",
    "\n",
    "# the first fixed image will be the reference slice\n",
    "fixed_image_itk = itk.GetImageFromArray(im[0])\n",
    "for z in tqdm(range(1, n_slices)):\n",
    "# for z in tqdm(range(1, 6)):\n",
    "\n",
    "    # the moving image is the current slice\n",
    "    moving_image_itk = itk.GetImageFromArray(im[z])\n",
    "\n",
    "    # perform the pairwise registration between two slices \n",
    "    transformed_moving_image, result_transform_parameters = itk.elastix_registration_method(\n",
    "        fixed_image_itk,\n",
    "        moving_image_itk,\n",
    "        parameter_object=registration_parameter_object,\n",
    "        log_to_console=False\n",
    "        )\n",
    "\n",
    "    # set the current moving image as the fixed image for the registration in the next iteration\n",
    "    fixed_image_itk = moving_image_itk\n",
    "\n",
    "    # append the obtained transform to the transform parameter object\n",
    "    curr_transform_object.AddParameterMap(result_transform_parameters.GetParameterMap(0))\n",
    "\n",
    "    # transform the current slice and append it to the reconstructed stack\n",
    "    curr_slice = itk.transformix_filter(moving_image_itk, curr_transform_object)\n",
    "    corrected_slices.append(np.array(curr_slice))\n",
    "\n",
    "# convert the list of 2D slices into a 3D numpy array \n",
    "corrected_slices = np.array(corrected_slices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "7baadd3e-5903-428c-ab99-5f6bebd8a45d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Image layer 'After correction' at 0x17f2ab400>"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import napari\n",
    "viewer = napari.Viewer()\n",
    "\n",
    "viewer.add_image(im, name='Before correction')\n",
    "viewer.add_image(corrected_slices, name='After correction')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df33a33a-693a-48eb-9518-194dc0ee97c5",
   "metadata": {},
   "source": [
    "## Exercise: Drift correction\n",
    "\n",
    "Can you use a similar approach to perform drift correction of a timelapse?\n",
    "\n",
    "There's an example dataset available for this at '../example_data/2d_movie.tif'."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
